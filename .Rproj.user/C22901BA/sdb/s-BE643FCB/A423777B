{
    "collab_server" : "",
    "contents" : "---\ntitle: \"predicao-deputados\"\nauthor: \"Lucas Diniz\"\ndate: \"16/12/2017\"\noutput: \n  html_document:\n    toc: true\n    toc_float: true\n    fig_width: 12\n    fig_heigth: 10\n---\n\n\nNeste lab iremos tunar modelos de regressão preditivos para a votação de deputados federais.\n\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\nlibrary('caret')\nlibrary('tidyverse')\n\nset.seed(1321)\n\ndados_treino <- read_csv('dados/train.csv') %>%\n  filter(nome != \"JAIR MESSIAS BOLSONARO\" & nome != \"CELSO UBIRAJARA RUSSOMANNO\") %>%\n  select(-cargo, -nome)\n\ndados_teste <- read_csv(\"dados/test.csv\")%>%\n  select(-cargo, -nome)\n\ndados_teste[is.na(dados_teste)] <- 0\n\n\ntrain_control<- trainControl(method=\"cv\", number=10) #10-fold-cross-validation\n\n\n```\n\n##1) Usando todas as variáveis disponíveis, tune (usando validação cruzada): \n\n###(i) um modelo de regressão Ridge\n\nPara tunar o parâmetro lambda do modelo de regressão ridge foi utilizada 10-fold-cross-validation realizando uma busca sobre um grid com cem valores possíveis para lambda, este foi tunado de tal forma que o RMSE de cross-validation fosse minimizado. Assim, o modelo ótimo obtido para todas as variáveis teve lambda igual </b>0.2848036</b>, RMSE de aproximadamente <b>47996.61</b> e Rsquared de aproximadamente <b>0.38</b>.\n\n  \n```{r warning=FALSE}\n\n  grid_ridge <- expand.grid(lambda = 10^seq(10, -2, length=100))\n\n  model.ridge <- train(votos ~ ., \n                       data = dados_treino, \n                       trControl = train_control, \n                       method = \"ridge\", \n                       tuneGrid = grid_ridge, \n                       na.action = na.omit)\n  print(model.ridge)\n  \n```\n  \n\n###(ii) um modelo de regressão Lasso\n\nPara tunar o modelo de regressão lasso foi utilizado um grid com diversos valores de lambda que foram iterados com o objetivo de minimizar o RMSE. Ao fim da validação cruzada o modelo obtido possuia lambda igual a <b>0.9</b>, já o RMSE ficou em <b>40742.61</b> e o Rsquared em <b>0.4318561</b>.\n  \n  \n```{r warning=FALSE}\ngrid_lasso <- expand.grid(fraction = seq(from = 0, to = 1, by = 0.1))\n\n\nmodel.lasso <- train(votos ~ .,\n                     data = dados_treino,\n                     trControl = train_control,\n                     method = \"lasso\",\n                     tuneGrid = grid_lasso,\n                     na.action = na.omit)\n\nprint(model.lasso)\n```\n\n\n###(iii) um modelo KNN\n\nNo modelo KNN o parâmetro tunado foi o número k de vizinhos e a métrica utilizada foi novamente o RMSE. Para o modelo KNN com todas as variáveis o número ótimo de vizinhos k foi igual a <b>9</b> e isso resultou em um erro de validação cruazada de <b>46522.24</b> e um Rsquared de <b>0.3625683</b>.\n\n```{r}\n\nmodel.knn <- \n  train(votos ~ ., \n        data = dados_treino, \n        trControl = train_control, \n        method = \"knn\",\n        metric = \"RMSE\",\n        tuneLength = 20,\n        na.action = na.omit)\n\nprint(model.knn)\n```\n\n##2) Compare os três modelos em termos do erro RMSE de validação cruzada.\n\nUtilizando todas as variáveis o modelo Lasso se saiu melhor que Ridge e KNN. Contudo isso é de se esperar uma vez que a regressão Lasso zera os parâmetros que considera menos importantes, diferentemente da regressão Ridge que apenas os aproxima de zero. Neste caso como temos uma grande confusão de parâmetros é provavél que a regressão Ridge tenha considerado parâmetros não importantes no modelo e por isso o bias foi maior. Já para o knn não podemos garantir que a função de distância sendo utilizada é positiva (podem haver parâmetros com valores negativos) e mesmo que ela seja positiva existem muitos parâmetros influenciando o cálculo da distância, portanto é de se esperar que o KNN tenha nos retornado o pior RMSE dentre os três algoritmos executados.\n\n\n\n##3) Quais as variáveis mais importantes segundo o modelo de regressão Ridge e Lasso?  Variáveis foram descartadas pelo Lasso? Quais?\n\n###Coeficientes obtidos pela regressão ridge:\n\n```{r}\n\nelasticnet::predict.enet(model.ridge$finalModel, s = model.ridge$bestTune$lambda, mode='fraction')$coefficients\n\n```\n\nAs variáveis mais importantse para o modelo Ridge foram:\n\n<b>quantidade_doacoes</b> com um coeficiente de <b>51.127623355</b>\n<b>quantidade_despesas</b> com um coeficiente de <b>1.054121819</b>                                                                   <b>total_receita</b> com um coeficiente de <b>0.010513379</b> \n\n###Coeficientes obtidos pela regressão Lasso:\n\nA regressão Lasso parece ter dado importância a todos os parâmetros, além disso temos coeficientes muito altos o que pode ser um sinal de overfitting. Contudo, isso é de se esperar uma vez que não tunamos o parâmetro alpha.  \n\n```{r}\n\nelasticnet::predict.enet(model.lasso$finalModel, s = model.lasso$bestTune$fraction, mode='fraction')$coefficients\n\n\n```\n\n\n##4) Re-treine o melhor modelo (usando os melhores valores de parâmetros encontrados em todos os dados, sem usar validação cruzada).\n\nO melhor modelo obtido durante a análise utilizou o algoritmo KNN usando o parâmetro k = 9. Ess modelo apresentou 22800 de RMSE com os dados de treino.\n\nAs variáveis explicativas utilizadas foram as seguintes:\n\n<b>total_despesa:</b> O total gasto (sem considerar caixa 2) por cada deputado.\n<b>quantidade_doadores:</b> O número de doadores da campanha do deputado.\n<b>partido * UF:</b> A interação entre a varíavel partido e a váriável estado. Achei interessante incluir essa interação pois alguns partidos são mais fortes em certos estados, o que teoricamente daria vantagem aos candidatos desses partidos.\n\n\n```{r}\n\ntrain_control_final<- trainControl(method=\"cv\", number = 2) #sem cross validation\n\nmodel.final <- \n  train(votos ~ total_despesa + quantidade_doadores + partido * UF, \n        data = dados_treino, \n        method = \"knn\",\n        metric = \"RMSE\",\n        tuneLength = 3,\n        trControl = train_control_final,\n        na.action = na.omit)\n\nprint(model.final)\n\n```\n\n##5) Use esse último modelo treinado para prever os dados de teste disponíveis no challenge que criamos na plataforma Kaggle\n\nO modelo foi utilizado para prever os dados de teste e o resultado foi submetido na plataforma Kaggle e foi rankeado com 44704 de RMSE para os dados de teste.\n\n```{r}\nsubmit_kaggle <- dados_teste %>% \n  select(ID) %>% \n  mutate(votos = round(predict(model.final, newdata = dados_teste)))\n\nwrite_csv(submit_kaggle, \"result.csv\")\n\n```\n",
    "created" : 1519645861692.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3654138299",
    "id" : "A423777B",
    "lastKnownWriteTime" : 1519645854,
    "last_content_update" : 1519645854,
    "path" : "~/Downloads/predicao-deputados (1).Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}